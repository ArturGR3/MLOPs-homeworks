{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This jupyter notebook covers part of the project related to:\n",
    "\n",
    "1) Data acquisition (Kaggle competition using Kaggle API)\n",
    "2) Data type optimization for memory usage reduction and preparing data to run automated feature engineering\n",
    "3) Feature enginering (using automated feature engineering framework OpenFE)\n",
    "4) Creation of machine learning model using Autogluon (AutoML framework) and experimentation tracking using MlFlow\n",
    "5) Getting the model from s3 bucket using MlflowClient\n",
    "5) Predicting on the test set and submiting results to Kaggle competition \n",
    "\n",
    "The part with model deployment as web-service and monitoring will be covered in the folder web_service_mlflow_visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "- [Importing Libraries](#importing-libraries)\n",
    "- [Connecting to Kaggle Competition and Downloading Data](#connecting-to-kaggle-competition-and-downloading-data)\n",
    "- [Data Preprocessing](#data-preprocessing)\n",
    "- [Automated Feature Engineering using OpenFe](#automated-feature-engineering-using-openfe)\n",
    "- [Model Building using AutoGluon and Tracking using MLflow Server](#model-building-using-autogluon-and-tracking-using-mlflow-server)\n",
    "- [Submitting Results to Kaggle Competition and Storing Results in MLflow](#submitting-results-to-kaggle-competition-and-storing-results-in-mlflow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries\n",
    "\n",
    "You can notice below that most of the code is wrapped in custom modules. \n",
    "1) kaggle_client - is a kaggle API wrapper that allows to download test, train, and submition files. It also provides a convinient way to submit results to kaggle competetion.\n",
    "2) data_preprocesing - is used for data type optimization and preparing data for automated feature enginerring framework OpenFE.\n",
    "3) feature_engineering - is a wrapper around OpenFE, where creates stratified sample and uses it to create new features from existing ones. More detail look in [feature_engineering.ipynb](https://github.com/ArturGR3/MLOPs-homeworks/blob/main/project/mlops_project/feature_engineering/feature_engineering.ipynb)\n",
    "4) mlflow_client - is a wrapper around Autogluon (AutoML framework) and Mlflow experiment tracking.\n",
    "5) download_folder_s3 - is used to pull folder from S3 bucket. We will need this to bring in AutoGluon model back from S3 for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project path /workspaces/MLOPs-homeworks/project/mlops_project\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from mlflow.tracking import MlflowClient\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import logging\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Make sure that correct .env is loaded\n",
    "load_dotenv(find_dotenv(filename=\"mlops_project.env\", usecwd=True, raise_error_if_not_found=True))\n",
    "project_path = os.getenv(\"PROJECT_PATH\")\n",
    "print(f\"project path {project_path}\")\n",
    "\n",
    "# Make sure that the project path is in the sys.path to be able to import modules\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "# Import custom modules\n",
    "from modules.kaggle_client import KaggleClient \n",
    "from modules.data_preprocesing import DataPreprocessor \n",
    "from modules.feature_engineering import FeatureEnginering \n",
    "from modules.mlflow_client import MLflowAutoGluon \n",
    "from modules.download_folder_s3 import download_s3_folder, list_files_in_s3_folder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to Kaggle Competition and Downloading Data\n",
    "\n",
    "We are using one of the tabular playground searies [Regression with a Tabular Media Campaign Cost Dataset](https://www.kaggle.com/competitions/playground-series-s3e11/overview) that aim to predict the cost of media campaign. This analysis could be easily replicated to other tabular series by changing below parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the competition name and target column\n",
    "competition_name = \"playground-series-s3e11\"\n",
    "autogluon_preset = 'best_quality'\n",
    "run_time = 1\n",
    "target = \"cost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded /workspaces/MLOPs-homeworks/project/mlops_project/data/playground-series-s3e11/raw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv', 'sample_submission.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize KaggleClient to be able to talk to kaggle API\n",
    "kaggle_client = KaggleClient(competition_name=competition_name, target_column=target)\n",
    "# Downloads raw data for a given competition locally to the data folder\n",
    "kaggle_client.download_data()\n",
    "# Show the content of the data folder\n",
    "os.listdir(f\"{project_path}/data/{competition_name}/raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "Here were will perform some data types optimization techniques to reduce the storage size and efficiency of the models that we are building. Some of the optimization techniques include:\n",
    "1) Downcasting numeric columns to reduce memory usage.\n",
    "2) Converting object columns to category or datetime columns based on uniqueness.\n",
    "3) Converting float columns to integer columns if all fractional parts are 0.\n",
    "4) Replacing some of the special characters in column names to '_' to be able to feed the dataset to OpenFe.\n",
    "\n",
    "All the data type changes and column name transformations will be stored in convinient json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data to adjust data types and reduce memory usage\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "data_preprocessor = DataPreprocessor(competition_name)\n",
    "train = pd.read_csv(os.path.join(data_preprocessor.df_raw_path, \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(data_preprocessor.df_raw_path, \"test.csv\"))\n",
    "submission = pd.read_csv(os.path.join(data_preprocessor.df_raw_path, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_sales(in millions)</th>\n",
       "      <td>8.61</td>\n",
       "      <td>5.00</td>\n",
       "      <td>14.08</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_sales(in millions)</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_children</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_children_at_home</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_cars_at home(approx).1</th>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gross_weight</th>\n",
       "      <td>10.30</td>\n",
       "      <td>6.66</td>\n",
       "      <td>21.30</td>\n",
       "      <td>14.80</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recyclable_package</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_fat</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>units_per_case</th>\n",
       "      <td>32.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_sqft</th>\n",
       "      <td>36509.00</td>\n",
       "      <td>28206.00</td>\n",
       "      <td>21215.00</td>\n",
       "      <td>21215.00</td>\n",
       "      <td>27694.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coffee_bar</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_store</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salad_bar</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared_food</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florist</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost</th>\n",
       "      <td>62.09</td>\n",
       "      <td>121.80</td>\n",
       "      <td>83.51</td>\n",
       "      <td>66.78</td>\n",
       "      <td>111.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0         1         2         3         4\n",
       "id                              0.00      1.00      2.00      3.00      4.00\n",
       "store_sales(in millions)        8.61      5.00     14.08      4.02      2.13\n",
       "unit_sales(in millions)         3.00      2.00      4.00      3.00      3.00\n",
       "total_children                  2.00      4.00      0.00      5.00      5.00\n",
       "num_children_at_home            2.00      0.00      0.00      0.00      0.00\n",
       "avg_cars_at home(approx).1      2.00      3.00      3.00      0.00      3.00\n",
       "gross_weight                   10.30      6.66     21.30     14.80     17.00\n",
       "recyclable_package              1.00      1.00      1.00      0.00      1.00\n",
       "low_fat                         0.00      0.00      0.00      1.00      1.00\n",
       "units_per_case                 32.00      1.00     26.00     36.00     20.00\n",
       "store_sqft                  36509.00  28206.00  21215.00  21215.00  27694.00\n",
       "coffee_bar                      0.00      1.00      1.00      1.00      1.00\n",
       "video_store                     0.00      0.00      0.00      0.00      1.00\n",
       "salad_bar                       0.00      0.00      0.00      0.00      1.00\n",
       "prepared_food                   0.00      0.00      0.00      0.00      1.00\n",
       "florist                         0.00      0.00      0.00      0.00      1.00\n",
       "cost                           62.09    121.80     83.51     66.78    111.51"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data before preprocessing\n",
    "train.head(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the logging below, you can notice that storage memory reduced by around 78% which is pretty significant, given that we did not loose much information in converting these columns to more optimal data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 08:27:38,243 - modules.data_preprocesing - INFO - Initial memory usage: 0.045640 GB\n",
      "2024-07-23 08:27:38,391 - modules.data_preprocesing - INFO - Final memory usage: 0.010739 GB\n",
      "2024-07-23 08:27:38,392 - modules.data_preprocesing - INFO - Memory reduced by 0.034901 GB (76.47%).\n",
      "2024-07-23 08:27:38,409 - modules.data_preprocesing - INFO - Data stored in /workspaces/MLOPs-homeworks/project/mlops_project/data/playground-series-s3e11/preprocessed/data_dtype_optimized.pkl\n",
      "2024-07-23 08:27:38,410 - modules.data_preprocesing - INFO - JSON data saved to /workspaces/MLOPs-homeworks/project/mlops_project/data/playground-series-s3e11/preprocessed/column_changes.json\n",
      "2024-07-23 08:27:38,413 - modules.data_preprocesing - INFO - JSON data saved to /workspaces/MLOPs-homeworks/project/mlops_project/data/playground-series-s3e11/preprocessed/dtype_changes.json\n",
      "2024-07-23 08:27:38,416 - modules.data_preprocesing - INFO - Initial memory usage: 0.028637 GB\n",
      "2024-07-23 08:27:38,482 - modules.data_preprocesing - INFO - Final memory usage: 0.006264 GB\n",
      "2024-07-23 08:27:38,483 - modules.data_preprocesing - INFO - Memory reduced by 0.022373 GB (78.12%).\n",
      "2024-07-23 08:27:38,498 - modules.data_preprocesing - INFO - Data stored in /workspaces/MLOPs-homeworks/project/mlops_project/data/playground-series-s3e11/preprocessed/data_dtype_optimized.pkl\n",
      "2024-07-23 08:27:38,499 - modules.data_preprocesing - INFO - JSON data saved to /workspaces/MLOPs-homeworks/project/mlops_project/data/playground-series-s3e11/preprocessed/column_changes.json\n",
      "2024-07-23 08:27:38,500 - modules.data_preprocesing - INFO - JSON data saved to /workspaces/MLOPs-homeworks/project/mlops_project/data/playground-series-s3e11/preprocessed/dtype_changes.json\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "train = data_preprocessor.optimize_dtypes(train)\n",
    "test = data_preprocessor.optimize_dtypes(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see the mapping of old column names to new columns from json file that we stored after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                    id\n",
       "store_sales(in millions)        store_sales_in_millions_\n",
       "unit_sales(in millions)          unit_sales_in_millions_\n",
       "total_children                            total_children\n",
       "num_children_at_home                num_children_at_home\n",
       "avg_cars_at home(approx).1    avg_cars_at_home_approx__1\n",
       "gross_weight                                gross_weight\n",
       "recyclable_package                    recyclable_package\n",
       "low_fat                                          low_fat\n",
       "units_per_case                            units_per_case\n",
       "store_sqft                                    store_sqft\n",
       "coffee_bar                                    coffee_bar\n",
       "video_store                                  video_store\n",
       "salad_bar                                      salad_bar\n",
       "prepared_food                              prepared_food\n",
       "florist                                          florist\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming columns\n",
    "with open(\"/workspaces/MLOPs-homeworks/project/mlops_project/data/playground-series-s3e11/preprocessed/column_changes.json\", \"r\") as f:\n",
    "    column_changes = json.load(f)\n",
    "column_changes = pd.Series(column_changes)\n",
    "column_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see what were the data types changes, you can notice that some of the heavy float64 data types moved to int8, that significantly reduced that memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_dtype</th>\n",
       "      <th>new_dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>units_per_case</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared_food</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florist</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_store</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_sqft</th>\n",
       "      <td>float64</td>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_children_at_home</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_sales_in_millions_</th>\n",
       "      <td>float64</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gross_weight</th>\n",
       "      <td>float64</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_cars_at_home_approx__1</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_children</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_sales_in_millions_</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_fat</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coffee_bar</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salad_bar</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recyclable_package</th>\n",
       "      <td>float64</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>int64</td>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           old_dtype new_dtype\n",
       "units_per_case               float64      int8\n",
       "prepared_food                float64      int8\n",
       "florist                      float64      int8\n",
       "video_store                  float64      int8\n",
       "store_sqft                   float64     int32\n",
       "num_children_at_home         float64      int8\n",
       "store_sales_in_millions_     float64   float32\n",
       "gross_weight                 float64   float32\n",
       "avg_cars_at_home_approx__1   float64      int8\n",
       "total_children               float64      int8\n",
       "unit_sales_in_millions_      float64      int8\n",
       "low_fat                      float64      int8\n",
       "coffee_bar                   float64      int8\n",
       "salad_bar                    float64      int8\n",
       "recyclable_package           float64      int8\n",
       "id                             int64     int32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing data types\n",
    "with open(\"/workspaces/MLOPs-homeworks/project/mlops_project/data/playground-series-s3e11/preprocessed/dtype_changes.json\", \"r\") as f:\n",
    "    dtype_changes = json.load(f)\n",
    "df_dtype_changes = pd.DataFrame(dtype_changes)\n",
    "df_dtype_changes.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated Feature Engineering using OpenFE library\n",
    "We use open source package [OpenFE](https://github.com/IIIS-Li-Group/OpenFE) for automated feature engineering. It takes time to run this process on relatevilly large datasets, thus we perform stratified subsampling to be able to create features faster. More in depth analysis about this technique and effect of new features on model performance you can find it this [Medium article](paste a link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:27<00:00,  1.70s/it]\n",
      "100%|██████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "100%|██████████| 16/16 [00:15<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 generated features are:\n",
      "GroupByThenMean(video_store,store_sqft)\n",
      "Combine(store_sqft,salad_bar)\n",
      "GroupByThenStd(avg_cars_at_home_approx__1,store_sqft)\n",
      "(total_children+store_sqft)\n",
      "CombineThenFreq(total_children,store_sqft)\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering with OpenFE\n",
    "feature_engineering = FeatureEnginering(competition_name, target_column=\"cost\")\n",
    "train_transformed, test_transformend = feature_engineering.openfe_transform(train, test)\n",
    "\n",
    "# Saving transformed data\n",
    "train_transformed = pd.read_pickle(\n",
    "    filepath_or_buffer=f\"{project_path}/data/{competition_name}/feature_engineered/train_transformed.pkl\"\n",
    ")\n",
    "test_transformed = pd.read_pickle(\n",
    "    filepath_or_buffer=f\"{project_path}/data/{competition_name}/feature_engineered/test_transformed.pkl\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building using AutoGluon and Tracking using MLflow Server\n",
    "For model building we will use AutoML library AutoGluon, that provides and easy way to create an ansamble of models with hyperparameter tuning in couple lines of code. \n",
    "We will use Mlflow server in EC2 with S3 bucker as artifact store to keep track of model performance. Autogluon provides a way to store the model specifically for deployment, reducing the memory requirement. This model we will use for model deployment as web service in the second part of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create autogloun model using MlfLow server in EC2 and store artifacts in S3\n",
    "# You need to make sure that EC2 instance is running the server\n",
    "tracking_server = os.getenv(\"TRACKING_SERVER_HOST\")\n",
    "artifact_path_s3 = os.getenv(\"AWS_BUCKET_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow_autogluon_remote_aws_ec2 = MLflowAutoGluon(\n",
    "    tracking_server=\"remote\",\n",
    "    backend_store=tracking_server,\n",
    "    artifact_location=f\"s3://{artifact_path_s3}\",\n",
    "    experiment_name=\"test\",\n",
    "    competition_name=competition_name,\n",
    "    target_name=target,\n",
    ")\n",
    "mlflow_autogluon_remote_aws_ec2.train_and_log_model(\n",
    "    presets=preset,\n",
    "    target=target,\n",
    "    train_transformed=train_transformed,\n",
    "    test_transformed=test_transformed,\n",
    "    run_time=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting Results to Kaggle Competition and Storing Results in MLflow\n",
    "We will use our model to create predictiong for Kaggle competition and use Kaggle API to submit our results. For that we will use MlflowClient to get the experiment name, experiment id and run_id. We will need this information to download the model from s3 bucket locally to perform prediction on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 1\n",
      "Name: test\n",
      "Artifact Location: s3://mlflow-artifact-ag3/1\n",
      "Lifecycle Stage: active\n",
      "---\n",
      "Experiment ID: 0\n",
      "Name: Default\n",
      "Artifact Location: s3://mlflow-artifact-ag3/0\n",
      "Lifecycle Stage: active\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Lets pull the model from s3 bucket where we stored it \n",
    "# For that we need to get the empexperiment id and run id using MflfowClient\n",
    "mlflow_client = MlflowClient(f'http://{tracking_server}:5000')\n",
    "# list all the experiments \n",
    "experiments = mlflow_client.search_experiments()\n",
    "\n",
    "for experiment in experiments:\n",
    "    print(f\"Experiment ID: {experiment.experiment_id}\")\n",
    "    print(f\"Name: {experiment.name}\")\n",
    "    print(f\"Artifact Location: {experiment.artifact_location}\")\n",
    "    print(f\"Lifecycle Stage: {experiment.lifecycle_stage}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 1, Run ID: 9dfdbe1b14924bdd9ce0e5da7b8c90c9\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"test\"\n",
    "experiment = mlflow_client.get_experiment_by_name(experiment_name)\n",
    "run_name = 'best_quality'\n",
    "\n",
    "# Search for runs with the specified run name\n",
    "runs = mlflow_client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=f\"tags.mlflow.runName = '{run_name}'\"\n",
    ")\n",
    "\n",
    "experiment_id = experiment.experiment_id\n",
    "if runs:\n",
    "    run_id = runs[0].info.run_id\n",
    "    print(f\"Experiment ID: {experiment.experiment_id}, Run ID: {run_id}\")\n",
    "else:\n",
    "    print(\"No run found with the specified name.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a convinient function list_files_in_s3_folder to list contents of the s3 folder where we stored our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 09:08:39,869 - botocore.credentials - INFO - Found credentials in environment variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/learner.pkl\n",
      "1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/metadata.json\n",
      "1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/LightGBMXT_BAG_L1_FULL/S1F1/model.pkl\n",
      "1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/trainer.pkl\n",
      "1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/predictor.pkl\n",
      "1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/version.txt\n"
     ]
    }
   ],
   "source": [
    "s3_folder = f\"{experiment_id}/{run_id}/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/\"\n",
    "list_files_in_s3_folder(bucket_name=artifact_path_s3, s3_folder=s3_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my research you can pull files one at a time from s3 bucket, but there is not straight way to bring in the folder with all its contents. I build the function download_s3_folder that does that. Below we store our model locally to further use it for predicting on the test set and deploy it as web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/learner.pkl\n",
      "Downloaded 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/learner.pkl to /workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11/learner.pkl\n",
      "Downloading 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/metadata.json\n",
      "Downloaded 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/metadata.json to /workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11/metadata.json\n",
      "Downloading 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/LightGBMXT_BAG_L1_FULL/S1F1/model.pkl\n",
      "Downloaded 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/LightGBMXT_BAG_L1_FULL/S1F1/model.pkl to /workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11/models/LightGBMXT_BAG_L1_FULL/S1F1/model.pkl\n",
      "Downloading 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Downloaded 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/LightGBMXT_BAG_L1_FULL/model.pkl to /workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Downloading 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Downloaded 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/LightGBM_BAG_L1/utils/model_template.pkl to /workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Downloading 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "Downloaded 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/WeightedEnsemble_L2_FULL/model.pkl to /workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "Downloading 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/trainer.pkl\n",
      "Downloaded 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/models/trainer.pkl to /workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11/models/trainer.pkl\n",
      "Downloading 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/predictor.pkl\n",
      "Downloaded 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/predictor.pkl to /workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11/predictor.pkl\n",
      "Downloading 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/version.txt\n",
      "Downloaded 1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/version.txt to /workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11/version.txt\n",
      "Successfully downloaded folder '1/9dfdbe1b14924bdd9ce0e5da7b8c90c9/artifacts/AutoGluon_mlflow_best_quality_deployment/artifacts/AutoGluon_mlflow_best_quality_deployment/' from bucket 'mlflow-artifact-ag3' to '/workspaces/MLOPs-homeworks/project/mlops_project/model/playground-series-s3e11'\n"
     ]
    }
   ],
   "source": [
    "download_s3_folder(bucket_name=artifact_path_s3, \n",
    "                   s3_folder=s3_folder, \n",
    "                   local_dir=f\"{project_path}/model/{competition_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autogluon provides a convinient way to load the model using TabularPredictor.load method, we use it to bring in model and create predictions for the test set. We store results as csv file to further submit it to Kaggle competetion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for predictions \n",
    "predictor = TabularPredictor.load(f\"{project_path}/model/{competition_name}\")\n",
    "# Create a folder for submitions \n",
    "submission_path = f\"data/{competition_name}/submission_files\"\n",
    "os.makedirs(submission_path, exist_ok=True)\n",
    "# Make predictions\n",
    "submission[target] = predictor.predict(test_transformed)\n",
    "submission_file = f\"{submission_path}/sub_{run_time}_{autogluon_preset}.csv\"\n",
    "submission.to_csv(submission_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our kaggle client to submit the results to the competition and get the score back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.82M/3.82M [00:01<00:00, 2.91MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission data/playground-series-s3e11/submission_files/sub_1_best_quality.csv for playground-series-s3e11 using best_quality: 'AutoGluon best_quality 1 min'\n",
      "Submission score: 0.30522\n"
     ]
    }
   ],
   "source": [
    "# Submit the file to Kaggle\n",
    "kaggle_score = kaggle_client.submit(\n",
    "    submission_file=submission_file,\n",
    "    model_name=autogluon_preset,\n",
    "    message=f\"AutoGluon {autogluon_preset} {run_time} min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we store kaggle score in Mlflow for our experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the new metric to the existing run\n",
    "metric_name = \"kaggle_score\"\n",
    "metric_value = kaggle_score\n",
    "\n",
    "# Log the kaggle score\n",
    "mlflow_client.log_metric(run_id, metric_name, metric_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within MlflowAutogluon class I have implemented 2 other options to track experiments: \n",
    "1) No tracking server, with local backend and artifact store\n",
    "2) With local tracking server, with sqlite backend store and local filesystem for artifacts.\n",
    "\n",
    "For the sake of simplicity I left them here commented, but user can try them on if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2:\n",
    "## Tracking server: no\n",
    "## Backend store: local filesystem\n",
    "## Artifacts store: local filesystem\n",
    "\n",
    "## --------------------\n",
    "# mlflow_autogluon_local = MLflowAutoGluon(\n",
    "#     tracking_server=\"no\",\n",
    "#     backend_store=f\"{project_path}/mlruns\",\n",
    "#     artifact_location=f\"{project_path}/mlruns\",\n",
    "#     experiment_name=\"test\",\n",
    "#     competition_name=competition_name,\n",
    "#     target_name=target,\n",
    "# )\n",
    "# mlflow_autogluon_local.train_and_log_model(\n",
    "#     presets=[\"medium_quality\"],\n",
    "#     target=target,\n",
    "#     train_transformed=train_transformed,\n",
    "#     test_transformed=test_transformed,\n",
    "#     run_time=1,\n",
    "#     for_deployment=True,\n",
    "#     for_kaggle_submission=False,\n",
    "# )\n",
    "## --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3:\n",
    "## tracking server: yes, local server\n",
    "## backend store: sqlite database\n",
    "## artifacts store: local filesystem\n",
    "\n",
    "## --------------------\n",
    "# mlflow_autogluon_local_server = MLflowAutoGluon(\n",
    "#     tracking_server=\"local\",\n",
    "#     backend_store=f\"{project_path}/backend.db\",\n",
    "#     artifact_location=f\"{project_path}/mlruns\",\n",
    "#     experiment_name=\"test_32\",\n",
    "#     competition_name=competition_name,\n",
    "#     target_name=target,\n",
    "# )\n",
    "# mlflow_autogluon_local_server.train_and_log_model(\n",
    "#     presets=[\"best_quality\"],\n",
    "#     target=target,\n",
    "#     train_transformed=train_transformed,\n",
    "#     test_transformed=test_transformed,\n",
    "#     run_time=1,\n",
    "# )\n",
    "## --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion and Next steps\n",
    "\n",
    "Things to add: \n",
    "1) automatic pull of experiment name, id, run_id, without manually adding them. \n",
    "2) add screenshots from the Mlflow with kaggle score and supporting models.\n",
    "\n",
    "The first part of the project that covers parts from getting the data and building the model for deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
